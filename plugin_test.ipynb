{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \" 31D_SRA2QTe3\"\n",
    "openai.api_base = \"https://api.openai-go.com/v1\"\n",
    "\n",
    "\n",
    "chat_completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{ \"role\": \"user\", \"content\": \"Hello world\" }]\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt \"Hello, Who are you?\" is most likely to begin a chat.\n",
      "77\n",
      "begin_chat\n",
      "The user asked, \"Hello, who are you?\" and the AI responded, \"Hello! I'm an AI language model developed by OpenAI. I'm here to help answer your questions and have a friendly chat. How can I assist you today?\"\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Function modules\n",
    "def math_module(prompt):\n",
    "    print(\"math prompt: \", prompt)\n",
    "    expression_response = chat_with_gpt([\n",
    "        {\"role\": \"user\", \"content\": f\"Please extract the math expression from: '{prompt}', in the format: 'expression:3+5'.\"}\n",
    "    ])\n",
    "    print(expression_response)\n",
    "    if  expression_response.startswith(\"expression:\"):\n",
    "        try:\n",
    "            return str(eval(expression_response.split(\"expression:\")[1].strip()))\n",
    "        except Exception as e:\n",
    "            return str(e)\n",
    "\n",
    "\n",
    "def weather_module(prompt):\n",
    "    city_response = chat_with_gpt([\n",
    "        {\"role\": \"user\", \"content\": f\"Please extract the city name from: '{prompt}'.\"}\n",
    "    ])\n",
    "    return f\"Weather for {city_response}: Sunny\"\n",
    "\n",
    "openai.api_key = \" 31D_SRA2QTe3\"\n",
    "openai.api_base = \"https://api.openai-go.com/v1\"\n",
    "\n",
    "def chat_with_gpt(messages):\n",
    "    chat_completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "def chat(prompt):\n",
    "    return chat_with_gpt([\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}.\"}\n",
    "    ])\n",
    "# Dictionary mapping keywords to function modules\n",
    "FUNCTION_MAP = {\n",
    "    \"calculate\": math_module,\n",
    "    \"check_weather\": weather_module,\n",
    "    \"begin_chat\": chat\n",
    "}\n",
    "\n",
    "def main():\n",
    "\n",
    "    user_message = input(\"Enter your prompt: \")\n",
    "    \n",
    "    options = \", \".join(FUNCTION_MAP.keys())\n",
    "    action_response = chat_with_gpt([\n",
    "        {\"role\": \"user\", \"content\": f\"What the prompt: '{user_message}' mostlikely to do? Options are: {options}\"}\n",
    "    ])\n",
    "    print(action_response)\n",
    "    # Fuzzy match the response with predefined labels\n",
    "    best_match, score = process.extractOne(action_response, FUNCTION_MAP.keys())\n",
    "    print(score)\n",
    "    print(best_match)\n",
    "    if score > 50:  # You can adjust the threshold as needed\n",
    "        result = FUNCTION_MAP[best_match](user_message)\n",
    "        action_response = chat_with_gpt([\n",
    "        {\"role\": \"user\", \"content\": f\"Please organize the user_message and the result into one general sentence: message:'{user_message}', result:{ result }\"}\n",
    "    ])\n",
    "        print(action_response)\n",
    "    else:\n",
    "        print(action_response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
